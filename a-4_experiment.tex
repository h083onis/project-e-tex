\section*{A-4. モデルの学習と評価}
本プロジェクトでは，Raspberry Piを用いて取得したBLEスキャンデータと，作成した正解ラベルを用いて，5つの機械学習モデルを学習し，予測結果の評価を行う.以下にモデル構築の手順を示す．

\subsection*{4.1 データの分割}
まず始めに，モデルの学習と評価を行うためにデータを分割する．train\_test\_split 関数を用いて，訓練データ（60\%），検証データ（20\%），テストデータ（20\%）に分割する．ただし，random\_state=42とする．ここで，訓練データは972 サンプル，検証データは324 サンプル，テストデータは324 サンプルである．

\subsection*{4.2 モデルの定義}
本プロジェクトでは，2.4～2.6節で紹介した5種類の回帰モデルを使用する．各モデルの定義は，Pythonのコードとして以下のように記述される．
\begin{lstlisting}[style=mystyle, language=Python, caption=回帰モデルの定義, label={models}]
models = {
    "SVR": SVR(),
    "RFR": RandomForestRegressor(random_state=42),
    "XGBR": XGBRegressor(random_state=42),
    "LGBM": lgb.LGBMRegressor(random_state=42),
    "CatBoost": CatBoostRegressor(random_seed=42, verbose=0)
}
\end{lstlisting}

\subsection*{4.3 モデルのパラメータ調整}
各モデルのハイパーパラメータは，Optuna を用いて調整する．本実験では，検証データに対する MSE（平均二乗誤差）と MAE（平均絶対誤差）の正規化和が最小となるパラメータを最適解とし，探索を行う．

具体的には，モデル \( m \) に対する目的関数 \( L(m) \) を以下の式で定義する．
\begin{equation}
L(m) = \frac{\mathrm{MSE}(m)}{\mathrm{MSE}_{\mathrm{default}}(m)} + \frac{\mathrm{MAE}(m)}{\mathrm{MAE}_{\mathrm{default}}(m)}
\end{equation}
ここで，\( \mathrm{MSE}(m) \) および \( \mathrm{MAE}(m) \) はモデル \( m \) の検証データに対するMSEおよびMAEであり，  
\( \mathrm{MSE}_{\mathrm{default}}(m) \) および \( \mathrm{MAE}_{\mathrm{default}}(m) \) は，モデル \( m \) をデフォルトのパラメータ設定で学習し，検証データに対して評価した際のMSEおよびMAEである．Optuna はこの \( L(m) \) を最小化するように，各モデルのハイパーパラメータを最適化する．各モデルにおけるハイパーパラメータの探索範囲は，以下のとおり定義する．
\begin{lstlisting}[style=mystyle, language=Python, caption=各モデルのハイパーパラメータ探索範囲]
param_ranges = {
    "SVR": {
        "C": (0.01, 100, "log"),
        "epsilon": (0.001, 0.1, "log"),
        "kernel": ["linear", "poly", "rbf", "sigmoid"]
    },
    "RFR": {
        "n_estimators": range(500, 5001, 500),
        "max_depth": range(3, 11),
        "min_samples_split": range(2, 21)
    },
    "XGBR": {
        "n_estimators": range(500, 5001, 500),
        "max_depth": range(3, 11),
        "learning_rate": (0.001, 0.1, "log")
    },
    "LGBM": {
        "n_estimators": range(500, 5001, 500),
        "num_leaves": range(16, 257),
        "learning_rate": (0.001, 0.1, "log")
    },
    "CatBoost": {
        "iterations": range(500, 5001, 500),
        "depth": range(3, 11),
        "learning_rate": (0.001, 0.1, "log")
    }
}
\end{lstlisting}
ハイパーパラメータ探索後，Optuna で得られた最適なパラメータを用いて，各モデルを再学習する．最後に，再学習したモデルに対してテストデータを入力し，最終的なモデル性能を評価する．

\subsection*{4.4 評価方法}
本プロジェクトでは，3.4節で述べた評価指標を用いて，ハイパーパラメータ調整後の各モデルの性能を評価・比較する．そして，最も性能の良いモデルを，人数推定モデルとして採用する．

\section*{A-5. 計算環境}
本章では，モデルの学習および評価で使用した計算機環境およびライブラリのバージョンについて説明する．ハードウェアの仕様を表\ref{tab:server_specs}，リソースの割り当てを表\ref{tab:resource_allocation}に示す．また，本プロジェクトで使用したライブラリのバージョンを表\ref{tab:versions}に示す．本実験ではPython 3.10.13を使用した．
\begin{table}[htbp]
    \centering
    \doublerulesep=0.3pt
    \caption{計算サーバの本体仕様}
    \label{tab:server_specs}
    \begin{tabular}{l|c}
        \hline\hline\hline
        項目 & 仕様 \\
        \hline
        CPU  & AMD EPYC 7742 × 2（合計論理コア数 256） \\
        RAM  & 合計 2048GB（448GB × 5） \\
        GPU  & NVIDIA HGX A100 80GB × 5 \\
        \hline\hline\hline
    \end{tabular}
\end{table}

\begin{table}[htbp]
    \centering
    \doublerulesep=0.3pt
    \caption{計算リソースの割り当て}
    \label{tab:resource_allocation}
    \begin{tabular}{c|c|c|c}
        \hline\hline\hline
        CPU（相対ウェイト） & RAM & GPU & 共有メモリ \\
        \hline
        28コア，56スレッド/256 & 448GB & 80GB × 2 & 32GB  \\
        \hline\hline\hline
    \end{tabular}
\end{table}

\begin{table}[htbp]
    \centering
    \doublerulesep=0.3pt
    \caption{使用ライブラリのバージョン一覧}
    \label{tab:versions}
    \begin{tabular}{l|c}
        \hline\hline\hline
        ライブラリ & バージョン \\
        \hline
        pandas & 2.2.1 \\
        numpy & 1.26.4 \\
        optuna & 4.2.1 \\
        scikit-learn & 1.4.1.post1 \\
        xgboost & 2.1.2 \\
        lightgbm & 4.5.0 \\
        catboost & 1.2.7 \\
        \hline\hline\hline
    \end{tabular}
\end{table}

